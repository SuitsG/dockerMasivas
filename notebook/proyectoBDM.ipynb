{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><font color='steelblue'> <font size = \"5,5\">CORPORACIÓN UNIVERSITARIA MINUTO DE DIOS </font></center><br>\n",
    "<center><font color='steelblue'> <font size = \"5\">FACULTAD DE INGENIERÍA</font></center><br>\n",
    "<center><font color='steelblue'> <font size = \"4\">PROGRAMA INGENIERÍA DE SISTEMAS</font></center><br>\n",
    "<center><font color='steelblue'> <font size = \"3\">CURSO BASES DE DATOS MASIVAS</font></center><br>\n",
    "<center><font color=\"yellow\" size = \"4\" face = \"small fonts\">Proyecto Modular - Mojo</font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><font color=\"olive\" size = \"4\" face = \"small fonts\">DATOS DE LOS PARTICIPANTES DEL GRUPO</font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"yellow\" size = \"4\" face = \"small fonts\">NRC: 80132</font></center><br>\n",
    "<font color=\"yellow\" size = \"4\" face = \"small fonts\">Nombres: Laura Tatiana Bernal Yanquen, Daniel Yesid Casallas Páez</font></center><br>\n",
    "<font color=\"yellow\" size = \"4\" face = \"small fonts\">ID:857437</font></center><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"yellow\" size = \"4\" face = \"small fonts\">El taller retoma algunas de las instrucciones utilizadas a través del curso de Bases de Datos Masivas, tener en cuenta seguir los pasos requeridos.</font></center><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"yellow\" size = \"4\" face = \"small fonts\">Al Cargar los archivos dispuestos en la carpeta Poryecto final BDM se debe utilizar sentencias que no fijen el path, este debe se dinámico en caso de que se creen nuevos paquetes</font></center><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\" size = \"4\" face = \"small fonts\">El ejercicio consta de seguir el cuaderno y  realizar las tareas solicitadas, Utilizar y citar la documentación propia de cada una de las herramientas utilizadas para realizar el tratamiento a la data.</font></center><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"yellow\" size = \"4\" face = \"small fonts\">1. Configuración e importe de las librerias.</font></center><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Esta extencion permite que jupyter detecte cambios externos y recargue sin tener que reiniciar VSC\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar la librearia os para poder interactuar el sistema donde se esta ejecutando los archivos\n",
    "import os\n",
    "import requests\n",
    "import re\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"yellow\" size = \"4\" face = \"small fonts\">2. Configure y levante los contenedores necesarios para la actividad, recuerde que la arquitectura respeta a 3 contenedores con una distribucion de DBMongo en cada una de ellas, un contenedor que tiene configurado Mojolicious con todas sus dependencias junto con una base de datos Relacional la cual sera escogida a su gusto.</font></center><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moverse a la carpeta data donde estan los archivos para lanzar el docker\n",
    "os.chdir(\"../data\")\n",
    "# Crear y ejecutar el docker-compose.yml\n",
    "os.system(\"docker-compose up --build\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"yellow\" size = \"4\" face = \"small fonts\">3. Una vez tenga el contenedor arriba cargue los datos .Json, uno por cada contenedor DBMongo.</font></center><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"yellow\" size = \"4\" face = \"small fonts\">Tenga en cuenta que debe tener la replica de los formatos `JSon` en cada contenedor</font></center><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Con estos comandos se deben cargar los datos .json dentro de las mongoDB sin necesidad de una funcion.\n",
    "\n",
    "# Comando para importar personas.json\n",
    "os.system(\"docker cp ../data/personas.json core_container:/app/data/personas.json\")\n",
    "\n",
    "# Comando para importar articulos.json\n",
    "os.system(\"docker cp ../data/articulos.json core_container:/app/data/articulos.json\")\n",
    "\n",
    "# Comando para importar ventas.json\n",
    "os.system(\"docker cp ../data/ventas.json core_container:/app/data/ventas.json\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"yellow\" size = \"4\" face = \"small fonts\">Se debe colocar el puerto expuesto del contenedor `Mojo`, para llamar la función y cargar los datos</font></center><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar data a las Mongo a con la funcion\n",
    "requests.get(\"http://localhost:8080/load_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"yellow\" size = \"4\" face = \"small fonts\">4. Muestre los datos que fueron almacenados en cada una de las distribuciones de BDMongo.</font></center><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar conteo de documentos en la colección personas\n",
    "os.system(\"\")\n",
    "\n",
    "# Verificar conteo de documentos en la colección articulos\n",
    "os.system(\"\")\n",
    "\n",
    "# Verificar conteo de documentos en la colección ventas\n",
    "os.system(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"yellow\" size = \"4\" face = \"small fonts\">Consultar a tráves del puerto expuesto la data que se encuentran en las colecciones personas, articulos y ventas de DBMongo</font></center><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver personas en MongoDB\n",
    "personas = requests.get(\"http://localhost:8080/mongo/personas\")\n",
    "print(json.dumps(personas.json(), ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver articulos en MongoDB\n",
    "articulos = requests.get(\"http://localhost:8080/mongo/articulos\")\n",
    "print(json.dumps(articulos.json(), ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver ventas en MongoDB\n",
    "ventas = requests.get(\"http://localhost:8080/mongo/ventas\")\n",
    "print(json.dumps(ventas.json(), ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"yellow\" size = \"4\" face = \"small fonts\">5. Verifique la estructura y tipo de los datos almacenados en las distribuciones DBMongo, genere una ETL para almacenar cada una de las distribuciones en la base de datos Relacional que configuro con anterioridad, recuerde que cada distribucion debe ir en una tabla relacional respetando la integridad referencial.</font></center><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones en Python para obtener datos de MongoDB para articulos\n",
    "def limpiar_valor_numerico(valor):\n",
    "    \n",
    "    if valor is None:\n",
    "        return None\n",
    "    \n",
    "    # Convertir a string y limpiar espacios\n",
    "    valor_str = str(valor).strip()\n",
    "    \n",
    "    # Eliminar caracteres no numéricos (excepto el signo negativo al inicio)\n",
    "    valor_limpio = re.sub(r'[^\\d-]', '', valor_str)\n",
    "    \n",
    "    try:\n",
    "        return int(valor_limpio)\n",
    "    except (ValueError, TypeError):\n",
    "        return None\n",
    "    \n",
    "\n",
    "\n",
    "# Función para verificar y limpiar idArticulo y cantidadArticulo donde debe ser un dato entero, tener en cuenta elimiar el id que proporciona \n",
    "# DBMongo a cada uno de las colecciones para cargarla a la Bases de Datos Relacional en SQLlite que importo.\n",
    "def filtrar_y_limpiar_articulos(datos):\n",
    "    # Definir los campos que necesitan ser numéricos\n",
    "    campos_a_limpiar = ['idArticulo', 'cantidadArticulo']\n",
    "    datos_limpios = []\n",
    "    \n",
    "    # Primera fase: Limpiar datos\n",
    "    for documento in datos:\n",
    "        # Eliminar el _id de MongoDB\n",
    "        if '_id' in documento:\n",
    "            del documento['_id']\n",
    "        \n",
    "        campos_validos = True\n",
    "        \n",
    "        # Validar y limpiar campos numéricos\n",
    "        for campo in campos_a_limpiar:\n",
    "            valor_limpio = limpiar_valor_numerico(documento.get(campo))\n",
    "            \n",
    "            if valor_limpio is None:\n",
    "                campos_validos = False\n",
    "                break\n",
    "            \n",
    "            documento[campo] = valor_limpio\n",
    "        \n",
    "        # Limpiar precioArticulo (puede ser float)\n",
    "        if 'precioArticulo' in documento:\n",
    "            try:\n",
    "                precio_str = str(documento['precioArticulo']).strip()\n",
    "                documento['precioArticulo'] = float(re.sub(r'[^\\d.-]', '', precio_str))\n",
    "            except (ValueError, TypeError):\n",
    "                campos_validos = False\n",
    "        \n",
    "        if campos_validos:\n",
    "            datos_limpios.append(documento)\n",
    "    \n",
    "    # Segunda fase: Consolidar artículos duplicados\n",
    "    articulos_dict = {}\n",
    "    \n",
    "    for articulo in datos_limpios:\n",
    "        id_articulo = articulo['idArticulo']\n",
    "        \n",
    "        if id_articulo not in articulos_dict:\n",
    "            # Primer registro de este artículo\n",
    "            articulos_dict[id_articulo] = {\n",
    "                'idArticulo': id_articulo,\n",
    "                'nombreArticulo': articulo.get('nombreArticulo', ''),\n",
    "                'cantidadArticulo': articulo['cantidadArticulo'],\n",
    "                'precioArticulo': articulo.get('precioArticulo', 0),\n",
    "                'suma_precios': articulo.get('precioArticulo', 0),\n",
    "                'contador': 1\n",
    "            }\n",
    "        else:\n",
    "            # Artículo duplicado: sumar cantidad y precios\n",
    "            articulos_dict[id_articulo]['cantidadArticulo'] += articulo['cantidadArticulo']\n",
    "            articulos_dict[id_articulo]['suma_precios'] += articulo.get('precioArticulo', 0)\n",
    "            articulos_dict[id_articulo]['contador'] += 1\n",
    "    \n",
    "    # Tercera fase: Calcular promedio de precios\n",
    "    articulos_consolidados = []\n",
    "    for articulo in articulos_dict.values():\n",
    "        articulo['precioArticulo'] = round(articulo['suma_precios'] / articulo['contador'], 2)\n",
    "        # Eliminar campos auxiliares\n",
    "        del articulo['suma_precios']\n",
    "        del articulo['contador']\n",
    "        articulos_consolidados.append(articulo)\n",
    "    \n",
    "    return articulos_consolidados\n",
    "\n",
    "\n",
    "# Uso de la función\n",
    "response = requests.get(\"http://localhost:8080/mongo/articulos\")\n",
    "articulos = response.json()\n",
    "articulos_limpios = filtrar_y_limpiar_articulos(articulos)\n",
    "print(json.dumps(articulos_limpios, ensure_ascii=False, indent=2))\n",
    "\n",
    "# Insertar en SQLite\n",
    "for articulo in articulos_limpios:\n",
    "    try:\n",
    "        response = requests.post(\"http://localhost:8080/sqlite/articulos\", json=articulo)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Error al insertar artículo {articulo.get('idArticulo')}: {response.json()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Excepción al insertar artículo: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener datos de MongoDB para personas, escriba un ETL donde haga la validación de numeroDocumento y telefono, asegurando que solo contengan valores \n",
    "# numéricos, tener en cuenta elimiar el id que proporciona DBMongo a cada uno de las colecciones para cargarla a la Bases de Datos Relacional en SQLlite que importo.\n",
    "\n",
    "def filtrar_limpiar_personas(personas, ventas):\n",
    "    \"\"\"\n",
    "    ETL para limpiar y validar datos de personas y ventas.\n",
    "    Primero valida los números de documento sin limpiar asociados a ventas.\n",
    "    Agrega identificadores temporales para rastrear ventas originales.\n",
    "    Maneja duplicados de numeroDocumento y asegura integridad referencial.\n",
    "    \"\"\"\n",
    "    # Paso 1: Identificar números de documento asociados a ventas (sin limpiar)\n",
    "    compradores_en_ventas_raw = set()\n",
    "    \n",
    "    for venta in ventas:\n",
    "        id_comprador_raw = venta.get('idComprador')\n",
    "        if id_comprador_raw is not None:\n",
    "            compradores_en_ventas_raw.add(str(id_comprador_raw))\n",
    "    \n",
    "    print(f\"Números de documento sin limpiar en ventas: {len(compradores_en_ventas_raw)}\")\n",
    "    \n",
    "    # Paso 2: Limpiar datos de ventas y agregar identificador temporal\n",
    "    ventas_limpias = []\n",
    "    compradores_en_ventas = set()\n",
    "    \n",
    "    for idx, venta in enumerate(ventas):\n",
    "        # Eliminar _id de MongoDB\n",
    "        if '_id' in venta:\n",
    "            del venta['_id']\n",
    "        \n",
    "        # Agregar identificador temporal para rastreo\n",
    "        venta['_temp_id_venta'] = f\"VENTA_{idx}\"\n",
    "        \n",
    "        # Validar campos numéricos\n",
    "        id_venta = limpiar_valor_numerico(venta.get('idVenta'))\n",
    "        id_comprador = limpiar_valor_numerico(venta.get('idComprador'))\n",
    "        id_articulo = limpiar_valor_numerico(venta.get('idArticulo'))\n",
    "        cantidad = limpiar_valor_numerico(venta.get('cantidadProductos'))\n",
    "        \n",
    "        if None in [id_venta, id_comprador, id_articulo, cantidad]:\n",
    "            continue\n",
    "        \n",
    "        # Limpiar precioTotal\n",
    "        try:\n",
    "            precio_total = float(re.sub(r'[^\\d.-]', '', str(venta.get('precioTotal', 0))))\n",
    "        except (ValueError, TypeError):\n",
    "            continue\n",
    "        \n",
    "        venta['idVenta'] = id_venta\n",
    "        venta['idComprador'] = id_comprador\n",
    "        venta['_temp_doc_original'] = id_comprador  # Guardar documento original\n",
    "        venta['idArticulo'] = id_articulo\n",
    "        venta['cantidadProductos'] = cantidad\n",
    "        venta['precioTotal'] = round(precio_total, 2)\n",
    "        \n",
    "        ventas_limpias.append(venta)\n",
    "        compradores_en_ventas.add(id_comprador)\n",
    "    \n",
    "    print(f\"Números de documento limpios en ventas: {len(compradores_en_ventas)}\")\n",
    "    \n",
    "    # Paso 3: Limpiar y preparar datos de personas (solo las que tienen ventas)\n",
    "    personas_limpias = []\n",
    "    \n",
    "    for idx, persona in enumerate(personas):\n",
    "        # Eliminar _id de MongoDB\n",
    "        if '_id' in persona:\n",
    "            del persona['_id']\n",
    "        \n",
    "        # Verificar si el documento sin limpiar está en ventas\n",
    "        num_doc_raw = str(persona.get('numeroDocumento', ''))\n",
    "        if num_doc_raw not in compradores_en_ventas_raw:\n",
    "            continue\n",
    "        \n",
    "        # Validar y limpiar numeroDocumento (debe ser numérico)\n",
    "        num_doc = limpiar_valor_numerico(persona.get('numeroDocumento'))\n",
    "        if num_doc is None or num_doc not in compradores_en_ventas:\n",
    "            continue\n",
    "        \n",
    "        # Agregar identificador temporal para rastreo\n",
    "        persona['_temp_id_persona'] = f\"PERSONA_{idx}_DOC_{num_doc}\"\n",
    "        \n",
    "        # Validar y limpiar telefono (debe ser numérico)\n",
    "        telefono = persona.get('telefono', '')\n",
    "        if telefono:\n",
    "            telefono_limpio = re.sub(r'[^\\d]', '', str(telefono).strip())\n",
    "            persona['telefono'] = telefono_limpio if telefono_limpio else None\n",
    "        else:\n",
    "            persona['telefono'] = None\n",
    "        \n",
    "        persona['numeroDocumento'] = num_doc\n",
    "        persona['_temp_doc_original'] = num_doc  # Guardar documento original\n",
    "        personas_limpias.append(persona)\n",
    "    \n",
    "    # Paso 4: Resolver duplicados en personas\n",
    "    personas_dict = {}\n",
    "    nuevo_documento = 100000000  # Número de documento para reasignar\n",
    "    mapeo_documentos = {}  # Mapea: (doc_original, temp_id_persona) -> nuevo_doc\n",
    "    \n",
    "    for persona in personas_limpias:\n",
    "        num_doc = persona['numeroDocumento']\n",
    "        temp_id = persona['_temp_id_persona']\n",
    "        \n",
    "        if num_doc not in personas_dict:\n",
    "            # Primera vez que vemos este documento\n",
    "            personas_dict[num_doc] = persona\n",
    "            mapeo_documentos[(num_doc, temp_id)] = num_doc\n",
    "        else:\n",
    "            # Duplicado encontrado: reasignar número de documento\n",
    "            while nuevo_documento in personas_dict or nuevo_documento in compradores_en_ventas:\n",
    "                nuevo_documento += 1\n",
    "            \n",
    "            print(f\"Duplicado detectado: documento {num_doc} -> reasignado a {nuevo_documento}\")\n",
    "            \n",
    "            # Actualizar ventas que referencian este duplicado específico\n",
    "            for venta in ventas_limpias:\n",
    "                if venta['_temp_doc_original'] == num_doc:\n",
    "                    # Aquí deberías tener lógica adicional para determinar\n",
    "                    # a cuál persona pertenece esta venta específica\n",
    "                    # Por ahora, asignamos al nuevo documento\n",
    "                    venta['idComprador'] = nuevo_documento\n",
    "            \n",
    "            mapeo_documentos[(num_doc, temp_id)] = nuevo_documento\n",
    "            persona['numeroDocumento'] = nuevo_documento\n",
    "            personas_dict[nuevo_documento] = persona\n",
    "            compradores_en_ventas.add(nuevo_documento)\n",
    "            nuevo_documento += 1\n",
    "    \n",
    "    # Paso 5: Eliminar identificadores temporales\n",
    "    personas_finales = []\n",
    "    for persona in personas_dict.values():\n",
    "        if '_temp_id_persona' in persona:\n",
    "            del persona['_temp_id_persona']\n",
    "        if '_temp_doc_original' in persona:\n",
    "            del persona['_temp_doc_original']\n",
    "        personas_finales.append(persona)\n",
    "    \n",
    "    ventas_finales = []\n",
    "    for venta in ventas_limpias:\n",
    "        if '_temp_id_venta' in venta:\n",
    "            del venta['_temp_id_venta']\n",
    "        if '_temp_doc_original' in venta:\n",
    "            del venta['_temp_doc_original']\n",
    "        ventas_finales.append(venta)\n",
    "    \n",
    "    return personas_finales, ventas_finales\n",
    "\n",
    "\n",
    "personas = requests.get(\"http://localhost:8080/mongo/personas\").json()\n",
    "ventas = requests.get(\"http://localhost:8080/mongo/ventas\").json()\n",
    "\n",
    "personas_limpias, ventas_limpias = filtrar_limpiar_personas(personas, ventas)\n",
    "\n",
    "# Insertar en SQLite\n",
    "for persona in personas_limpias:\n",
    "    try:\n",
    "        response = requests.post(\"http://localhost:8080/sqlite/personas\", json=persona)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Error al insertar persona {persona.get('idPersona')}: {response.json()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Excepción al insertar persona: {e}\")\n",
    "\n",
    "# Insertar en SQLite\n",
    "for venta in ventas_limpias:\n",
    "    try:\n",
    "        response = requests.post(\"http://localhost:8080/sqlite/ventas\", json=venta)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Error al insertar venta {venta.get('idVenta')}: {response.json()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Excepción al insertar venta: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener datos de MongoDB para ventas, escriba un ETL donde haga la validación de idComprador, idArticulo y cantidadProductos asegurando que solo contengan valores \n",
    "# numéricos, tener en cuenta elimiar el id que proporciona DBMongo a cada uno de las colecciones para cargarla a la Bases de Datos Relacional en SQLlite que importo.\n",
    "\n",
    "\n",
    "# Obtener datos de MongoDB para ventas\n",
    "response = requests.get(\"http://localhost:8080/mongo/ventas\")\n",
    "ventas = response.json()\n",
    "ventas_limpias = filtrar_y_limpiar(ventas, 'idVenta', 'idComprador', 'idArticulo', 'cantidadProductos')\n",
    "print(json.dumps(ventas_limpias, ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"yellow\" size = \"4\" face = \"small fonts\">6. Muestre la data almacenada en la base de datos Relacional que esta usando, tabla por tabla.</font></center><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar data almacenada en la tabla personas\n",
    "# Conectar a la base de datos SQLite\n",
    "conexion = sqlite3.connect('../data/data/almacen.sqlite')\n",
    "\n",
    "# Crear una consulta SQL y cargar los resultados en un DataFrame\n",
    "consulta = \"SELECT * FROM personas;\"\n",
    "\n",
    "df = pd.read_sql_query(consulta, conexion)\n",
    "\n",
    "# Mostrar los datos\n",
    "print(df)\n",
    "\n",
    "# Cerrar la conexión\n",
    "conexion.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar data almacenada en la tabla articulos\n",
    "# Conectar a la base de datos SQLite\n",
    "conexion = sqlite3.connect('../data/data/almacen.sqlite')\n",
    "\n",
    "# Crear una consulta SQL y cargar los resultados en un DataFrame\n",
    "consulta = \"SELECT * FROM articulos\"\n",
    "df = pd.read_sql_query(consulta, conexion)\n",
    "\n",
    "# Mostrar los datos\n",
    "print(df)\n",
    "\n",
    "# Cerrar la conexión\n",
    "conexion.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar data almacenada en la tabla ventas\n",
    "# Conectar a la base de datos SQLite\n",
    "conexion = sqlite3.connect('../data/data/almacen.sqlite')\n",
    "\n",
    "# Crear una consulta SQL y cargar los resultados en un DataFrame\n",
    "consulta = \"SELECT * FROM ventas;\"\n",
    "df = pd.read_sql_query(consulta, conexion)\n",
    "\n",
    "# Mostrar los datos\n",
    "print(df)\n",
    "\n",
    "# Cerrar la conexión\n",
    "conexion.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"yellow\" size = \"4\" face = \"small fonts\">7. Grafique los 5 articulos mas vendidos.</font></center><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conectar a la base de datos\n",
    "conexion = sqlite3.connect('../data/data/almacen.sqlite') \n",
    "\n",
    "  # Ejecutar la consulta y cargar los datos en un DataFrame\n",
    "consulta = \"\"\"SELECT\n",
    "    a.idArticulo,\n",
    "    a.nombreArticulo,\n",
    "    SUM(v.cantidadProductos) AS unidades_vendidas,\n",
    "    SUM(v.precioTotal)      AS ingresos_totales\n",
    "    FROM ventas v\n",
    "    JOIN articulos a ON a.idArticulo = v.idArticulo\n",
    "    GROUP BY a.idArticulo, a.nombreArticulo\n",
    "    ORDER BY unidades_vendidas DESC, ingresos_totales DESC, a.nombreArticulo ASC\n",
    "    LIMIT 5;\"\"\"\n",
    "\n",
    "\n",
    "df = pd.read_sql_query(consulta, conexion)\n",
    "\n",
    "# Cerrar la conexión\n",
    "conexion.close()\n",
    "\n",
    "# Graficar los datos\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(df['nombreArticulo'], df['unidades_vendidas'], color='skyblue')\n",
    "plt.title('Top 5 Artículos Más Vendidos')\n",
    "plt.xlabel('Artículo')\n",
    "plt.ylabel('Unidades Vendidas')\n",
    "plt.xticks(rotation=45)\n",
    "plt.gca().yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"yellow\" size = \"4\" face = \"small fonts\">8. Grafique los 5 compradores que han realizado más compras.</font></center><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conectar a la base de datos\n",
    "conexion = sqlite3.connect('../data/data/almacen.sqlite') \n",
    "\n",
    "# Ejecutar la consulta y cargar los datos en un DataFrame\n",
    "consulta = \"\"\"\n",
    "SELECT\n",
    "  p.numeroDocumento,\n",
    "  p.nombres,\n",
    "  p.primerApellido,\n",
    "  p.segundoApellido,\n",
    "  COUNT(*)                           AS compras_realizadas,\n",
    "  SUM(v.cantidadProductos)           AS unidades_compradas,\n",
    "  SUM(v.precioTotal)                 AS total_gastado\n",
    "FROM ventas v\n",
    "JOIN personas p ON p.numeroDocumento = v.idComprador\n",
    "GROUP BY p.numeroDocumento, p.nombres, p.primerApellido, p.segundoApellido\n",
    "ORDER BY unidades_compradas DESC, total_gastado DESC, p.primerApellido ASC, p.nombres ASC\n",
    "LIMIT 5;\n",
    "\"\"\"\n",
    "df = pd.read_sql_query(consulta, conexion)\n",
    "\n",
    "\n",
    "# Asegura tipos y arma el nombre completo de forma segura\n",
    "# Crear nombre completo del cliente\n",
    "df['cliente'] = (df['nombres'] + ' ' + df['primerApellido'] + ' ' + df['segundoApellido']).str.strip()\n",
    "\n",
    "# Graficar\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(df['cliente'], df['total_gastado'], color='lightcoral')\n",
    "plt.title('Top 5 Compradores que Más Han Comprado')\n",
    "plt.xlabel('Cliente')\n",
    "plt.ylabel('Total Gastado ($)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.gca().yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Cerrar la conexión\n",
    "conexion.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"yellow\" size = \"4\" face = \"small fonts\">9. Grafique la distribución de precios de los 5 primeros artículos .</font></center><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conectar a la base de datos\n",
    "conexion = sqlite3.connect('../data/data/almacen.sqlite') \n",
    "\n",
    "# Ejecutar la consulta y cargar los datos en un DataFrame\n",
    "consulta = \"\"\"\n",
    "SELECT\n",
    "  idArticulo,\n",
    "  nombreArticulo,\n",
    "  precioArticulo\n",
    "FROM articulos\n",
    "ORDER BY idArticulo ASC\n",
    "LIMIT 5;\n",
    "\"\"\"\n",
    "df = pd.read_sql_query(consulta, conexion)\n",
    "\n",
    "# Graficar\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(df['nombreArticulo'], df['precioArticulo'], color='lightgreen')\n",
    "plt.title('Distribución de Precios de los 5 Primeros Artículos')\n",
    "plt.xlabel('Artículo')\n",
    "plt.ylabel('Precio ($)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Cerrar la conexión\n",
    "conexion.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"yellow\" size = \"4\" face = \"small fonts\">10. Grafique los 5 artículos que menos se han vendido.</font></center><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conectar a la base de datos\n",
    "conexion = sqlite3.connect('../data/data/almacen.sqlite') \n",
    "\n",
    "# Ejecutar la consulta y cargar los datos en un DataFrame\n",
    "consulta = \"\"\"\n",
    "SELECT\n",
    "    a.idArticulo,\n",
    "    a.nombreArticulo,\n",
    "    COALESCE(SUM(v.cantidadProductos), 0) AS unidades_vendidas,\n",
    "    COALESCE(SUM(v.precioTotal), 0) AS ingresos_totales\n",
    "FROM articulos a\n",
    "LEFT JOIN ventas v ON a.idArticulo = v.idArticulo\n",
    "GROUP BY a.idArticulo, a.nombreArticulo\n",
    "ORDER BY unidades_vendidas ASC, ingresos_totales ASC, a.nombreArticulo ASC\n",
    "LIMIT 5;\n",
    "\"\"\"\n",
    "df = pd.read_sql_query(consulta, conexion)\n",
    "\n",
    "# Cerrar la conexión\n",
    "conexion.close()\n",
    "\n",
    "# Graficar los datos\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(df['nombreArticulo'], df['unidades_vendidas'], color='salmon')\n",
    "plt.title('Top 5 Artículos Menos Vendidos')\n",
    "plt.xlabel('Artículo')\n",
    "plt.ylabel('Unidades Vendidas')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.gca().yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
