{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><font color='steelblue'> <font size = \"5,5\">CORPORACIÓN UNIVERSITARIA MINUTO DE DIOS </font></center><br>\n",
    "<center><font color='steelblue'> <font size = \"5\">FACULTAD DE INGENIERÍA</font></center><br>\n",
    "<center><font color='steelblue'> <font size = \"4\">PROGRAMA INGENIERÍA DE SISTEMAS</font></center><br>\n",
    "<center><font color='steelblue'> <font size = \"3\">CURSO BASES DE DATOS MASIVAS</font></center><br>\n",
    "<center><font color=\"yellow\" size = \"4\" face = \"small fonts\">Proyecto Modular - Mojo</font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><font color=\"olive\" size = \"4\" face = \"small fonts\">DATOS DE LOS PARTICIPANTES DEL GRUPO</font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"yellow\" size = \"4\" face = \"small fonts\">NRC: 80132</font></center><br>\n",
    "<font color=\"yellow\" size = \"4\" face = \"small fonts\">Nombres: Laura Tatiana Bernal Yanquen, Daniel Yesid Casallas Páez</font></center><br>\n",
    "<font color=\"yellow\" size = \"4\" face = \"small fonts\">ID:857437</font></center><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"yellow\" size = \"4\" face = \"small fonts\">El taller retoma algunas de las instrucciones utilizadas a través del curso de Bases de Datos Masivas, tener en cuenta seguir los pasos requeridos.</font></center><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"yellow\" size = \"4\" face = \"small fonts\">Al Cargar los archivos dispuestos en la carpeta Poryecto final BDM se debe utilizar sentencias que no fijen el path, este debe se dinámico en caso de que se creen nuevos paquetes</font></center><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\" size = \"4\" face = \"small fonts\">El ejercicio consta de seguir el cuaderno y  realizar las tareas solicitadas, Utilizar y citar la documentación propia de cada una de las herramientas utilizadas para realizar el tratamiento a la data.</font></center><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"yellow\" size = \"4\" face = \"small fonts\">1. Configuración e importe de las librerias.</font></center><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Esta extencion permite que jupyter detecte cambios externos y recargue sin tener que reiniciar VSC\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar la librearia os para poder interactuar el sistema donde se esta ejecutando los archivos\n",
    "import os\n",
    "import requests\n",
    "import re\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from collections import defaultdict\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"yellow\" size = \"4\" face = \"small fonts\">2. Configure y levante los contenedores necesarios para la actividad, recuerde que la arquitectura respeta a 3 contenedores con una distribucion de DBMongo en cada una de ellas, un contenedor que tiene configurado Mojolicious con todas sus dependencias junto con una base de datos Relacional la cual sera escogida a su gusto.</font></center><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moverse a la carpeta data donde estan los archivos para lanzar el docker\n",
    "os.chdir(\"../data\")\n",
    "# Crear y ejecutar el docker-compose.yml\n",
    "os.system(\"docker-compose up --build\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"yellow\" size = \"4\" face = \"small fonts\">3. Una vez tenga el contenedor arriba cargue los datos .Json, uno por cada contenedor DBMongo.</font></center><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"yellow\" size = \"4\" face = \"small fonts\">Tenga en cuenta que debe tener la replica de los formatos `JSon` en cada contenedor</font></center><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Con estos comandos se deben cargar los datos .json dentro de las mongoDB sin necesidad de una funcion.\n",
    "\n",
    "# Comando para importar personas.json\n",
    "os.system(\"docker cp ../data/personas.json core_container:/app/data/personas.json\")\n",
    "\n",
    "# Comando para importar articulos.json\n",
    "os.system(\"docker cp ../data/articulos.json core_container:/app/data/articulos.json\")\n",
    "\n",
    "# Comando para importar ventas.json\n",
    "os.system(\"docker cp ../data/ventas.json core_container:/app/data/ventas.json\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"yellow\" size = \"4\" face = \"small fonts\">Se debe colocar el puerto expuesto del contenedor `Mojo`, para llamar la función y cargar los datos</font></center><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar data a las Mongo a con la funcion\n",
    "requests.get(\"http://localhost:8080/load_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"yellow\" size = \"4\" face = \"small fonts\">4. Muestre los datos que fueron almacenados en cada una de las distribuciones de BDMongo.</font></center><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar conteo de documentos en la colección personas\n",
    "os.system(\"\")\n",
    "\n",
    "# Verificar conteo de documentos en la colección articulos\n",
    "os.system(\"\")\n",
    "\n",
    "# Verificar conteo de documentos en la colección ventas\n",
    "os.system(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "🚀 ETL PARALELO - PROCESAMIENTO DE ALTO RENDIMIENTO\n",
      "💻 CPUs disponibles: 8\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "PASO 1/3: ARTÍCULOS\n",
      "======================================================================\n",
      "🚀 Procesando 10000 artículos con 8 workers...\n",
      "🚀 Procesando 10000 artículos con 8 workers...\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"../data\")\n",
    "from etl_paralelo import ejecutar_etl_paralelo\n",
    "\n",
    "ejecutar_etl_paralelo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"yellow\" size = \"4\" face = \"small fonts\">Consultar a tráves del puerto expuesto la data que se encuentran en las colecciones personas, articulos y ventas de DBMongo</font></center><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver personas en MongoDB\n",
    "personas = requests.get(\"http://localhost:8080/mongo/personas\")\n",
    "print(json.dumps(personas.json(), ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver articulos en MongoDB\n",
    "articulos = requests.get(\"http://localhost:8080/mongo/articulos\")\n",
    "print(json.dumps(articulos.json(), ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver ventas en MongoDB\n",
    "ventas = requests.get(\"http://localhost:8080/mongo/ventas\")\n",
    "print(json.dumps(ventas.json(), ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"yellow\" size = \"4\" face = \"small fonts\">5. Verifique la estructura y tipo de los datos almacenados en las distribuciones DBMongo, genere una ETL para almacenar cada una de las distribuciones en la base de datos Relacional que configuro con anterioridad, recuerde que cada distribucion debe ir en una tabla relacional respetando la integridad referencial.</font></center><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones en Python para obtener datos de MongoDB para articulos\n",
    "def limpiar_valor_numerico(valor):\n",
    "    \n",
    "    if valor is None:\n",
    "        return None\n",
    "    \n",
    "    # Convertir a string y limpiar espacios\n",
    "    valor_str = str(valor).strip()\n",
    "    \n",
    "    # Eliminar caracteres no numéricos (excepto el signo negativo al inicio)\n",
    "    valor_limpio = re.sub(r'[^\\d-]', '', valor_str)\n",
    "    \n",
    "    try:\n",
    "        return int(valor_limpio)\n",
    "    except (ValueError, TypeError):\n",
    "        return None\n",
    "    \n",
    "\n",
    "\n",
    "# Función para verificar y limpiar idArticulo y cantidadArticulo donde debe ser un dato entero, tener en cuenta elimiar el id que proporciona \n",
    "# DBMongo a cada uno de las colecciones para cargarla a la Bases de Datos Relacional en SQLlite que importo.\n",
    "def filtrar_y_limpiar_articulos(datos):\n",
    "    # Definir los campos que necesitan ser numéricos\n",
    "    campos_a_limpiar = ['idArticulo', 'cantidadArticulo']\n",
    "    datos_limpios = []\n",
    "    \n",
    "    # Primera fase: Limpiar datos\n",
    "    for documento in datos:\n",
    "        # Eliminar el _id de MongoDB\n",
    "        if '_id' in documento:\n",
    "            del documento['_id']\n",
    "        \n",
    "        campos_validos = True\n",
    "        \n",
    "        # Validar y limpiar campos numéricos\n",
    "        for campo in campos_a_limpiar:\n",
    "            valor_limpio = limpiar_valor_numerico(documento.get(campo))\n",
    "            \n",
    "            if valor_limpio is None:\n",
    "                campos_validos = False\n",
    "                break\n",
    "            \n",
    "            documento[campo] = valor_limpio\n",
    "        \n",
    "        # Limpiar precioArticulo (puede ser float)\n",
    "        if 'precioArticulo' in documento:\n",
    "            try:\n",
    "                precio_str = str(documento['precioArticulo']).strip()\n",
    "                documento['precioArticulo'] = float(re.sub(r'[^\\d.-]', '', precio_str))\n",
    "            except (ValueError, TypeError):\n",
    "                campos_validos = False\n",
    "        \n",
    "        if campos_validos:\n",
    "            datos_limpios.append(documento)\n",
    "    \n",
    "    # Segunda fase: Consolidar artículos por nombre\n",
    "    articulos_por_nombre = {}\n",
    "    \n",
    "    for articulo in datos_limpios:\n",
    "        nombre = articulo.get('nombreArticulo', '').strip()\n",
    "        \n",
    "        if nombre not in articulos_por_nombre:\n",
    "            articulos_por_nombre[nombre] = {\n",
    "                'nombreArticulo': nombre,\n",
    "                'cantidadArticulo': articulo['cantidadArticulo'],\n",
    "                'suma_precios': articulo.get('precioArticulo', 0),\n",
    "                'contador': 1,\n",
    "                'ids_anteriores': [articulo['idArticulo']]\n",
    "            }\n",
    "        else:\n",
    "            articulos_por_nombre[nombre]['cantidadArticulo'] += articulo['cantidadArticulo']\n",
    "            articulos_por_nombre[nombre]['suma_precios'] += articulo.get('precioArticulo', 0)\n",
    "            articulos_por_nombre[nombre]['contador'] += 1\n",
    "            articulos_por_nombre[nombre]['ids_anteriores'].append(articulo['idArticulo'])\n",
    "    \n",
    "    # Tercera fase: Crear nuevos IDs y mapeo\n",
    "    articulos_consolidados = []\n",
    "    mapeo_ids = {}\n",
    "    nuevo_id = 1\n",
    "    \n",
    "    for articulo in articulos_por_nombre.values():\n",
    "        articulo['precioArticulo'] = round(articulo['suma_precios'] / articulo['contador'], 2)\n",
    "        articulo['idArticulo'] = nuevo_id\n",
    "        \n",
    "        # Guardar mapeo de nuevo ID a IDs anteriores\n",
    "        mapeo_ids[nuevo_id] = articulo['ids_anteriores']\n",
    "        \n",
    "        # Eliminar campos auxiliares\n",
    "        del articulo['suma_precios']\n",
    "        del articulo['contador']\n",
    "        del articulo['ids_anteriores']\n",
    "        \n",
    "        articulos_consolidados.append(articulo)\n",
    "        nuevo_id += 1\n",
    "    \n",
    "    return articulos_consolidados, mapeo_ids\n",
    "\n",
    "\n",
    "# Uso de la función\n",
    "response = requests.get(\"http://localhost:8080/mongo/articulos\")\n",
    "articulos = response.json()\n",
    "articulos_limpios, mapeo_ids = filtrar_y_limpiar_articulos(articulos)\n",
    "print(json.dumps(articulos_limpios, ensure_ascii=False, indent=2))\n",
    "print(f\"\\nMapeo de IDs (nuevo -> anteriores): {mapeo_ids}\")\n",
    "\n",
    "# Insertar en SQLite\n",
    "for articulo in articulos_limpios:\n",
    "    try:\n",
    "        response = requests.post(\"http://localhost:8080/sqlite/articulos\", json=articulo)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Error al insertar artículo {articulo.get('idArticulo')}: {response.json()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Excepción al insertar artículo: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener datos de MongoDB para personas, escriba un ETL donde haga la validación de numeroDocumento y telefono, asegurando que solo contengan valores \n",
    "# numéricos, tener en cuenta elimiar el id que proporciona DBMongo a cada uno de las colecciones para cargarla a la Bases de Datos Relacional en SQLlite que importo.\n",
    "\n",
    "def filtrar_limpiar_personas(personas, ventas, mapeo_ids):\n",
    "    \"\"\"\n",
    "    ETL robusto sin _norm_num_str:\n",
    "    - Normaliza documento y teléfono.\n",
    "    - Elimina _id de Mongo.\n",
    "    - Solo conserva personas con ventas enlazables.\n",
    "    - Resuelve duplicados con sufijo incremental estable.\n",
    "    - Mapea idArticulo con mapeo_ids (normalizado).\n",
    "    - Descarta ventas sin comprador enlazable o con campos inválidos.\n",
    "    Retorna (personas_limpias, ventas_finales).\n",
    "    \"\"\"\n",
    "\n",
    "    # ---- 0) Mapeo de artículos: invertir + normalizar a int ----\n",
    "    mapeo_inverso = {}\n",
    "    for nuevo_id, ids_anteriores in (mapeo_ids or {}).items():\n",
    "        try:\n",
    "            nuevo_int = int(str(nuevo_id))\n",
    "        except Exception:\n",
    "            continue\n",
    "        for old in ids_anteriores or []:\n",
    "            try:\n",
    "                old_int = int(str(old))\n",
    "                mapeo_inverso[old_int] = nuevo_int\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "    # ---- 1) Preparar personas con id temporal y clave normalizada ----\n",
    "    personas_con_id_temp = []\n",
    "    id_temporal = 1\n",
    "\n",
    "    # doc_key (str del documento normalizado) -> lista[id_temp]\n",
    "    dockey_a_ids_temp = defaultdict(list)\n",
    "\n",
    "    for p in personas:\n",
    "        pc = dict(p)\n",
    "        pc.pop('_id', None)\n",
    "\n",
    "        num_doc = limpiar_valor_numerico(pc.get('numeroDocumento'))\n",
    "        if num_doc is None:\n",
    "            # No podremos emparejar esta persona\n",
    "            continue\n",
    "\n",
    "        doc_key = str(num_doc)  # <- reemplaza _norm_num_str\n",
    "\n",
    "        pc['_id_temp'] = id_temporal\n",
    "        pc['_doc_key'] = doc_key\n",
    "        dockey_a_ids_temp[doc_key].append(id_temporal)\n",
    "        personas_con_id_temp.append(pc)\n",
    "        id_temporal += 1\n",
    "\n",
    "    # ---- 2) Preasignar id_temp a ventas según comprador normalizado ----\n",
    "    ventas_con_id_temp = []\n",
    "    for v in ventas:\n",
    "        vc = dict(v)\n",
    "        vc.pop('_id', None)\n",
    "\n",
    "        comp_num = limpiar_valor_numerico(vc.get('idComprador'))\n",
    "        if comp_num is not None:\n",
    "            comp_key = str(comp_num)  # <- reemplaza _norm_num_str\n",
    "            if dockey_a_ids_temp.get(comp_key):\n",
    "                vc['_id_temp_comprador'] = dockey_a_ids_temp[comp_key][0]  # determinista (primero)\n",
    "\n",
    "        ventas_con_id_temp.append(vc)\n",
    "\n",
    "    # ---- 3) Limpiar ventas y filtrar las enlazables ----\n",
    "    ventas_limpias = []\n",
    "    compradores_necesarios = set()\n",
    "\n",
    "    for v in ventas_con_id_temp:\n",
    "        # Campos numéricos obligatorios\n",
    "        id_venta    = limpiar_valor_numerico(v.get('idVenta'))\n",
    "        id_articulo = limpiar_valor_numerico(v.get('idArticulo'))\n",
    "        cantidad    = limpiar_valor_numerico(v.get('cantidadProductos'))\n",
    "\n",
    "        if id_venta is None or id_articulo is None or cantidad is None:\n",
    "            continue\n",
    "\n",
    "        # Mapear artículo si corresponde\n",
    "        if id_articulo in mapeo_inverso:\n",
    "            id_articulo = mapeo_inverso[id_articulo]\n",
    "\n",
    "        # precioTotal robusto (permite símbolos)\n",
    "        raw_precio = str(v.get('precioTotal', 0))\n",
    "        raw_precio = re.sub(r'[^\\d.-]', '', raw_precio) or '0'\n",
    "        try:\n",
    "            precio_total = round(float(raw_precio), 2)\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "        # Necesitamos un id_temp de comprador válido para garantizar FK\n",
    "        id_temp_comp = v.get('_id_temp_comprador')\n",
    "        if not id_temp_comp:\n",
    "            # Venta sin persona enlazable → descartar (evita FK rota)\n",
    "            continue\n",
    "\n",
    "        compradores_necesarios.add(id_temp_comp)\n",
    "\n",
    "        # Cargar con placeholders; luego reemplazamos idComprador con doc final\n",
    "        v_clean = {\n",
    "            'idVenta': id_venta,\n",
    "            'idComprador': None,  # se asigna en el paso 5\n",
    "            'idArticulo': id_articulo,\n",
    "            'cantidadProductos': cantidad,\n",
    "            'precioTotal': precio_total,\n",
    "            '_id_temp_comprador': id_temp_comp\n",
    "        }\n",
    "        ventas_limpias.append(v_clean)\n",
    "\n",
    "    # ---- 4) Construir personas_limpias SOLO para compradores necesarios ----\n",
    "    personas_limpias = []\n",
    "    docs_usados = set()\n",
    "    contador_dups = defaultdict(int)  # num_doc_limpio -> contador\n",
    "    id_temp_a_doc_final = {}\n",
    "\n",
    "    for p in personas_con_id_temp:\n",
    "        if p['_id_temp'] not in compradores_necesarios:\n",
    "            continue\n",
    "\n",
    "        num_doc = limpiar_valor_numerico(p.get('numeroDocumento'))\n",
    "        if num_doc is None:\n",
    "            continue\n",
    "\n",
    "        # Resolver duplicados de forma determinista con sufijo incremental\n",
    "        if num_doc in docs_usados:\n",
    "            contador_dups[num_doc] += 1\n",
    "            num_doc_final = int(f\"{num_doc}{contador_dups[num_doc]}\")\n",
    "        else:\n",
    "            contador_dups[num_doc] = 0\n",
    "            num_doc_final = num_doc\n",
    "\n",
    "        docs_usados.add(num_doc_final)\n",
    "        id_temp_a_doc_final[p['_id_temp']] = num_doc_final\n",
    "\n",
    "        # Teléfono solo dígitos o None\n",
    "        tel = p.get('telefono')\n",
    "        if tel is not None:\n",
    "            tel_digits = re.sub(r'[^\\d]', '', str(tel).strip())\n",
    "            p['telefono'] = tel_digits if tel_digits else None\n",
    "        else:\n",
    "            p['telefono'] = None\n",
    "\n",
    "        # Asignar documento final y limpiar temporales\n",
    "        p['numeroDocumento'] = num_doc_final\n",
    "        p.pop('_id_temp', None)\n",
    "        p.pop('_doc_key', None)\n",
    "\n",
    "        personas_limpias.append(p)\n",
    "\n",
    "    # ---- 5) Actualizar ventas con documento final del comprador ----\n",
    "    ventas_finales = []\n",
    "    for v in ventas_limpias:\n",
    "        id_temp = v.pop('_id_temp_comprador', None)\n",
    "        doc_final = id_temp_a_doc_final.get(id_temp)\n",
    "        if not doc_final:\n",
    "            # No debería ocurrir (ya filtramos), pero por seguridad\n",
    "            continue\n",
    "        v['idComprador'] = doc_final\n",
    "        ventas_finales.append(v)\n",
    "\n",
    "    return personas_limpias, ventas_finales\n",
    "\n",
    "\n",
    "\n",
    "personas = requests.get(\"http://localhost:8080/mongo/personas\").json()\n",
    "ventas = requests.get(\"http://localhost:8080/mongo/ventas\").json()\n",
    "\n",
    "personas_limpias, ventas_limpias = filtrar_limpiar_personas(personas, ventas, mapeo_ids)\n",
    "\n",
    "# Insertar en SQLite\n",
    "for persona in personas_limpias:\n",
    "    try:\n",
    "        response = requests.post(\"http://localhost:8080/sqlite/personas\", json=persona)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Error al insertar persona {persona.get('numeroDocumento')}: {response.json()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Excepción al insertar persona: {e}\")\n",
    "\n",
    "for venta in ventas_limpias:\n",
    "    try:\n",
    "        response = requests.post(\"http://localhost:8080/sqlite/ventas\", json=venta)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Error al insertar venta {venta.get('idVenta')}: {response.json()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Excepción al insertar venta: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener datos de MongoDB para ventas, escriba un ETL donde haga la validación de idComprador, idArticulo y cantidadProductos asegurando que solo contengan valores \n",
    "# numéricos, tener en cuenta elimiar el id que proporciona DBMongo a cada uno de las colecciones para cargarla a la Bases de Datos Relacional en SQLlite que importo.\n",
    "\n",
    "\n",
    "# Obtener datos de MongoDB para ventas\n",
    "response = requests.get(\"http://localhost:8080/mongo/ventas\")\n",
    "ventas = response.json()\n",
    "ventas_limpias = filtrar_y_limpiar(ventas, 'idVenta', 'idComprador', 'idArticulo', 'cantidadProductos')\n",
    "print(json.dumps(ventas_limpias, ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"yellow\" size = \"4\" face = \"small fonts\">6. Muestre la data almacenada en la base de datos Relacional que esta usando, tabla por tabla.</font></center><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar data almacenada en la tabla personas\n",
    "# Conectar a la base de datos SQLite\n",
    "conexion = sqlite3.connect('../data/data/almacen.sqlite')\n",
    "\n",
    "# Crear una consulta SQL y cargar los resultados en un DataFrame\n",
    "consulta = \"SELECT * FROM personas;\"\n",
    "\n",
    "df = pd.read_sql_query(consulta, conexion)\n",
    "\n",
    "# Mostrar los datos\n",
    "print(df)\n",
    "\n",
    "# Cerrar la conexión\n",
    "conexion.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar data almacenada en la tabla articulos\n",
    "# Conectar a la base de datos SQLite\n",
    "conexion = sqlite3.connect('../data/data/almacen.sqlite')\n",
    "\n",
    "# Crear una consulta SQL y cargar los resultados en un DataFrame\n",
    "consulta = \"SELECT * FROM articulos\"\n",
    "df = pd.read_sql_query(consulta, conexion)\n",
    "\n",
    "# Mostrar los datos\n",
    "print(df)\n",
    "\n",
    "# Cerrar la conexión\n",
    "conexion.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar data almacenada en la tabla ventas\n",
    "# Conectar a la base de datos SQLite\n",
    "conexion = sqlite3.connect('../data/data/almacen.sqlite')\n",
    "\n",
    "# Crear una consulta SQL y cargar los resultados en un DataFrame\n",
    "consulta = \"SELECT * FROM ventas;\"\n",
    "df = pd.read_sql_query(consulta, conexion)\n",
    "\n",
    "# Mostrar los datos\n",
    "print(df)\n",
    "\n",
    "# Cerrar la conexión\n",
    "conexion.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"yellow\" size = \"4\" face = \"small fonts\">7. Grafique los 5 articulos mas vendidos.</font></center><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conectar a la base de datos\n",
    "conexion = sqlite3.connect('../data/data/almacen.sqlite') \n",
    "\n",
    "  # Ejecutar la consulta y cargar los datos en un DataFrame\n",
    "consulta = \"\"\"SELECT\n",
    "    a.idArticulo,\n",
    "    a.nombreArticulo,\n",
    "    SUM(v.cantidadProductos) AS unidades_vendidas,\n",
    "    SUM(v.precioTotal)      AS ingresos_totales\n",
    "    FROM ventas v\n",
    "    JOIN articulos a ON a.idArticulo = v.idArticulo\n",
    "    GROUP BY a.idArticulo, a.nombreArticulo\n",
    "    ORDER BY unidades_vendidas DESC, ingresos_totales DESC, a.nombreArticulo ASC\n",
    "    LIMIT 5;\"\"\"\n",
    "\n",
    "\n",
    "df = pd.read_sql_query(consulta, conexion)\n",
    "\n",
    "# Cerrar la conexión\n",
    "conexion.close()\n",
    "\n",
    "# Graficar los datos\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(df['nombreArticulo'], df['unidades_vendidas'], color='skyblue')\n",
    "plt.title('Top 5 Artículos Más Vendidos')\n",
    "plt.xlabel('Artículo')\n",
    "plt.ylabel('Unidades Vendidas')\n",
    "plt.xticks(rotation=45)\n",
    "plt.gca().yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"yellow\" size = \"4\" face = \"small fonts\">8. Grafique los 5 compradores que han realizado más compras.</font></center><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conectar a la base de datos\n",
    "conexion = sqlite3.connect('../data/data/almacen.sqlite') \n",
    "\n",
    "# Ejecutar la consulta y cargar los datos en un DataFrame\n",
    "consulta = \"\"\"\n",
    "SELECT\n",
    "  p.numeroDocumento,\n",
    "  p.nombres,\n",
    "  p.primerApellido,\n",
    "  p.segundoApellido,\n",
    "  COUNT(*)                           AS compras_realizadas,\n",
    "  SUM(v.cantidadProductos)           AS unidades_compradas,\n",
    "  SUM(v.precioTotal)                 AS total_gastado\n",
    "FROM ventas v\n",
    "JOIN personas p ON p.numeroDocumento = v.idComprador\n",
    "GROUP BY p.numeroDocumento, p.nombres, p.primerApellido, p.segundoApellido\n",
    "ORDER BY unidades_compradas DESC, total_gastado DESC, p.primerApellido ASC, p.nombres ASC\n",
    "LIMIT 5;\n",
    "\"\"\"\n",
    "df = pd.read_sql_query(consulta, conexion)\n",
    "\n",
    "\n",
    "# Asegura tipos y arma el nombre completo de forma segura\n",
    "# Crear nombre completo del cliente\n",
    "df['cliente'] = (df['nombres'] + ' ' + df['primerApellido'] + ' ' + df['segundoApellido']).str.strip()\n",
    "\n",
    "# Graficar\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(df['cliente'], df['total_gastado'], color='lightcoral')\n",
    "plt.title('Top 5 Compradores que Más Han Comprado')\n",
    "plt.xlabel('Cliente')\n",
    "plt.ylabel('Total Gastado ($)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.gca().yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Cerrar la conexión\n",
    "conexion.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"yellow\" size = \"4\" face = \"small fonts\">9. Grafique la distribución de precios de los 5 primeros artículos .</font></center><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conectar a la base de datos\n",
    "conexion = sqlite3.connect('../data/data/almacen.sqlite') \n",
    "\n",
    "# Ejecutar la consulta y cargar los datos en un DataFrame\n",
    "consulta = \"\"\"\n",
    "SELECT\n",
    "  idArticulo,\n",
    "  nombreArticulo,\n",
    "  precioArticulo\n",
    "FROM articulos\n",
    "ORDER BY idArticulo ASC\n",
    "LIMIT 5;\n",
    "\"\"\"\n",
    "df = pd.read_sql_query(consulta, conexion)\n",
    "\n",
    "# Graficar\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(df['nombreArticulo'], df['precioArticulo'], color='lightgreen')\n",
    "plt.title('Distribución de Precios de los 5 Primeros Artículos')\n",
    "plt.xlabel('Artículo')\n",
    "plt.ylabel('Precio ($)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Cerrar la conexión\n",
    "conexion.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"yellow\" size = \"4\" face = \"small fonts\">10. Grafique los 5 artículos que menos se han vendido.</font></center><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conectar a la base de datos\n",
    "conexion = sqlite3.connect('../data/data/almacen.sqlite') \n",
    "\n",
    "# Ejecutar la consulta y cargar los datos en un DataFrame\n",
    "consulta = \"\"\"\n",
    "SELECT\n",
    "    a.idArticulo,\n",
    "    a.nombreArticulo,\n",
    "    COALESCE(SUM(v.cantidadProductos), 0) AS unidades_vendidas,\n",
    "    COALESCE(SUM(v.precioTotal), 0) AS ingresos_totales\n",
    "FROM articulos a\n",
    "LEFT JOIN ventas v ON a.idArticulo = v.idArticulo\n",
    "GROUP BY a.idArticulo, a.nombreArticulo\n",
    "ORDER BY unidades_vendidas ASC, ingresos_totales ASC, a.nombreArticulo ASC\n",
    "LIMIT 5;\n",
    "\"\"\"\n",
    "df = pd.read_sql_query(consulta, conexion)\n",
    "\n",
    "# Cerrar la conexión\n",
    "conexion.close()\n",
    "\n",
    "# Graficar los datos\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(df['nombreArticulo'], df['unidades_vendidas'], color='salmon')\n",
    "plt.title('Top 5 Artículos Menos Vendidos')\n",
    "plt.xlabel('Artículo')\n",
    "plt.ylabel('Unidades Vendidas')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.gca().yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
