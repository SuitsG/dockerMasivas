{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><font color='steelblue'> <font size = \"5,5\">CORPORACI√ìN UNIVERSITARIA MINUTO DE DIOS </font></center><br>\n",
    "<center><font color='steelblue'> <font size = \"5\">FACULTAD DE INGENIER√çA</font></center><br>\n",
    "<center><font color='steelblue'> <font size = \"4\">PROGRAMA INGENIER√çA DE SISTEMAS</font></center><br>\n",
    "<center><font color='steelblue'> <font size = \"3\">CURSO BASES DE DATOS MASIVAS</font></center><br>\n",
    "<center><font color=\"yellow\" size = \"4\" face = \"small fonts\">Proyecto Modular - Mojo</font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><font color=\"olive\" size = \"4\" face = \"small fonts\">DATOS DE LOS PARTICIPANTES DEL GRUPO</font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"yellow\" size = \"4\" face = \"small fonts\">NRC: 80132</font></center><br>\n",
    "<font color=\"yellow\" size = \"4\" face = \"small fonts\">Nombres: Laura Tatiana Bernal Yanquen, Daniel Yesid Casallas P√°ez</font></center><br>\n",
    "<font color=\"yellow\" size = \"4\" face = \"small fonts\">ID:857437</font></center><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"yellow\" size = \"4\" face = \"small fonts\">El taller retoma algunas de las instrucciones utilizadas a trav√©s del curso de Bases de Datos Masivas, tener en cuenta seguir los pasos requeridos.</font></center><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"yellow\" size = \"4\" face = \"small fonts\">Al Cargar los archivos dispuestos en la carpeta Poryecto final BDM se debe utilizar sentencias que no fijen el path, este debe se din√°mico en caso de que se creen nuevos paquetes</font></center><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\" size = \"4\" face = \"small fonts\">El ejercicio consta de seguir el cuaderno y  realizar las tareas solicitadas, Utilizar y citar la documentaci√≥n propia de cada una de las herramientas utilizadas para realizar el tratamiento a la data.</font></center><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"yellow\" size = \"4\" face = \"small fonts\">1. Configuraci√≥n e importe de las librerias.</font></center><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Esta extencion permite que jupyter detecte cambios externos y recargue sin tener que reiniciar VSC\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar la librearia os para poder interactuar el sistema donde se esta ejecutando los archivos\n",
    "import os\n",
    "import requests\n",
    "import re\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from collections import defaultdict\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"yellow\" size = \"4\" face = \"small fonts\">2. Configure y levante los contenedores necesarios para la actividad, recuerde que la arquitectura respeta a 3 contenedores con una distribucion de DBMongo en cada una de ellas, un contenedor que tiene configurado Mojolicious con todas sus dependencias junto con una base de datos Relacional la cual sera escogida a su gusto.</font></center><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moverse a la carpeta data donde estan los archivos para lanzar el docker\n",
    "os.chdir(\"../data\")\n",
    "# Crear y ejecutar el docker-compose.yml\n",
    "os.system(\"docker-compose up --build\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"yellow\" size = \"4\" face = \"small fonts\">3. Una vez tenga el contenedor arriba cargue los datos .Json, uno por cada contenedor DBMongo.</font></center><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"yellow\" size = \"4\" face = \"small fonts\">Tenga en cuenta que debe tener la replica de los formatos `JSon` en cada contenedor</font></center><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Con estos comandos se deben cargar los datos .json dentro de las mongoDB sin necesidad de una funcion.\n",
    "\n",
    "# Comando para importar personas.json\n",
    "os.system(\"docker cp ../data/personas.json core_container:/app/data/personas.json\")\n",
    "\n",
    "# Comando para importar articulos.json\n",
    "os.system(\"docker cp ../data/articulos.json core_container:/app/data/articulos.json\")\n",
    "\n",
    "# Comando para importar ventas.json\n",
    "os.system(\"docker cp ../data/ventas.json core_container:/app/data/ventas.json\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"yellow\" size = \"4\" face = \"small fonts\">Se debe colocar el puerto expuesto del contenedor `Mojo`, para llamar la funci√≥n y cargar los datos</font></center><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar data a las Mongo a con la funcion\n",
    "requests.get(\"http://localhost:8080/load_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"yellow\" size = \"4\" face = \"small fonts\">4. Muestre los datos que fueron almacenados en cada una de las distribuciones de BDMongo.</font></center><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar conteo de documentos en la colecci√≥n personas\n",
    "os.system(\"\")\n",
    "\n",
    "# Verificar conteo de documentos en la colecci√≥n articulos\n",
    "os.system(\"\")\n",
    "\n",
    "# Verificar conteo de documentos en la colecci√≥n ventas\n",
    "os.system(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üöÄ ETL PARALELO - PROCESAMIENTO DE ALTO RENDIMIENTO\n",
      "üíª CPUs disponibles: 8\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "PASO 1/3: ART√çCULOS\n",
      "======================================================================\n",
      "üöÄ Procesando 10000 art√≠culos con 8 workers...\n",
      "üöÄ Procesando 10000 art√≠culos con 8 workers...\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"../data\")\n",
    "from etl_paralelo import ejecutar_etl_paralelo\n",
    "\n",
    "ejecutar_etl_paralelo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"yellow\" size = \"4\" face = \"small fonts\">Consultar a tr√°ves del puerto expuesto la data que se encuentran en las colecciones personas, articulos y ventas de DBMongo</font></center><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver personas en MongoDB\n",
    "personas = requests.get(\"http://localhost:8080/mongo/personas\")\n",
    "print(json.dumps(personas.json(), ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver articulos en MongoDB\n",
    "articulos = requests.get(\"http://localhost:8080/mongo/articulos\")\n",
    "print(json.dumps(articulos.json(), ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver ventas en MongoDB\n",
    "ventas = requests.get(\"http://localhost:8080/mongo/ventas\")\n",
    "print(json.dumps(ventas.json(), ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"yellow\" size = \"4\" face = \"small fonts\">5. Verifique la estructura y tipo de los datos almacenados en las distribuciones DBMongo, genere una ETL para almacenar cada una de las distribuciones en la base de datos Relacional que configuro con anterioridad, recuerde que cada distribucion debe ir en una tabla relacional respetando la integridad referencial.</font></center><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones en Python para obtener datos de MongoDB para articulos\n",
    "def limpiar_valor_numerico(valor):\n",
    "    \n",
    "    if valor is None:\n",
    "        return None\n",
    "    \n",
    "    # Convertir a string y limpiar espacios\n",
    "    valor_str = str(valor).strip()\n",
    "    \n",
    "    # Eliminar caracteres no num√©ricos (excepto el signo negativo al inicio)\n",
    "    valor_limpio = re.sub(r'[^\\d-]', '', valor_str)\n",
    "    \n",
    "    try:\n",
    "        return int(valor_limpio)\n",
    "    except (ValueError, TypeError):\n",
    "        return None\n",
    "    \n",
    "\n",
    "\n",
    "# Funci√≥n para verificar y limpiar idArticulo y cantidadArticulo donde debe ser un dato entero, tener en cuenta elimiar el id que proporciona \n",
    "# DBMongo a cada uno de las colecciones para cargarla a la Bases de Datos Relacional en SQLlite que importo.\n",
    "def filtrar_y_limpiar_articulos(datos):\n",
    "    # Definir los campos que necesitan ser num√©ricos\n",
    "    campos_a_limpiar = ['idArticulo', 'cantidadArticulo']\n",
    "    datos_limpios = []\n",
    "    \n",
    "    # Primera fase: Limpiar datos\n",
    "    for documento in datos:\n",
    "        # Eliminar el _id de MongoDB\n",
    "        if '_id' in documento:\n",
    "            del documento['_id']\n",
    "        \n",
    "        campos_validos = True\n",
    "        \n",
    "        # Validar y limpiar campos num√©ricos\n",
    "        for campo in campos_a_limpiar:\n",
    "            valor_limpio = limpiar_valor_numerico(documento.get(campo))\n",
    "            \n",
    "            if valor_limpio is None:\n",
    "                campos_validos = False\n",
    "                break\n",
    "            \n",
    "            documento[campo] = valor_limpio\n",
    "        \n",
    "        # Limpiar precioArticulo (puede ser float)\n",
    "        if 'precioArticulo' in documento:\n",
    "            try:\n",
    "                precio_str = str(documento['precioArticulo']).strip()\n",
    "                documento['precioArticulo'] = float(re.sub(r'[^\\d.-]', '', precio_str))\n",
    "            except (ValueError, TypeError):\n",
    "                campos_validos = False\n",
    "        \n",
    "        if campos_validos:\n",
    "            datos_limpios.append(documento)\n",
    "    \n",
    "    # Segunda fase: Consolidar art√≠culos por nombre\n",
    "    articulos_por_nombre = {}\n",
    "    \n",
    "    for articulo in datos_limpios:\n",
    "        nombre = articulo.get('nombreArticulo', '').strip()\n",
    "        \n",
    "        if nombre not in articulos_por_nombre:\n",
    "            articulos_por_nombre[nombre] = {\n",
    "                'nombreArticulo': nombre,\n",
    "                'cantidadArticulo': articulo['cantidadArticulo'],\n",
    "                'suma_precios': articulo.get('precioArticulo', 0),\n",
    "                'contador': 1,\n",
    "                'ids_anteriores': [articulo['idArticulo']]\n",
    "            }\n",
    "        else:\n",
    "            articulos_por_nombre[nombre]['cantidadArticulo'] += articulo['cantidadArticulo']\n",
    "            articulos_por_nombre[nombre]['suma_precios'] += articulo.get('precioArticulo', 0)\n",
    "            articulos_por_nombre[nombre]['contador'] += 1\n",
    "            articulos_por_nombre[nombre]['ids_anteriores'].append(articulo['idArticulo'])\n",
    "    \n",
    "    # Tercera fase: Crear nuevos IDs y mapeo\n",
    "    articulos_consolidados = []\n",
    "    mapeo_ids = {}\n",
    "    nuevo_id = 1\n",
    "    \n",
    "    for articulo in articulos_por_nombre.values():\n",
    "        articulo['precioArticulo'] = round(articulo['suma_precios'] / articulo['contador'], 2)\n",
    "        articulo['idArticulo'] = nuevo_id\n",
    "        \n",
    "        # Guardar mapeo de nuevo ID a IDs anteriores\n",
    "        mapeo_ids[nuevo_id] = articulo['ids_anteriores']\n",
    "        \n",
    "        # Eliminar campos auxiliares\n",
    "        del articulo['suma_precios']\n",
    "        del articulo['contador']\n",
    "        del articulo['ids_anteriores']\n",
    "        \n",
    "        articulos_consolidados.append(articulo)\n",
    "        nuevo_id += 1\n",
    "    \n",
    "    return articulos_consolidados, mapeo_ids\n",
    "\n",
    "\n",
    "# Uso de la funci√≥n\n",
    "response = requests.get(\"http://localhost:8080/mongo/articulos\")\n",
    "articulos = response.json()\n",
    "articulos_limpios, mapeo_ids = filtrar_y_limpiar_articulos(articulos)\n",
    "print(json.dumps(articulos_limpios, ensure_ascii=False, indent=2))\n",
    "print(f\"\\nMapeo de IDs (nuevo -> anteriores): {mapeo_ids}\")\n",
    "\n",
    "# Insertar en SQLite\n",
    "for articulo in articulos_limpios:\n",
    "    try:\n",
    "        response = requests.post(\"http://localhost:8080/sqlite/articulos\", json=articulo)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Error al insertar art√≠culo {articulo.get('idArticulo')}: {response.json()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Excepci√≥n al insertar art√≠culo: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener datos de MongoDB para personas, escriba un ETL donde haga la validaci√≥n de numeroDocumento y telefono, asegurando que solo contengan valores \n",
    "# num√©ricos, tener en cuenta elimiar el id que proporciona DBMongo a cada uno de las colecciones para cargarla a la Bases de Datos Relacional en SQLlite que importo.\n",
    "\n",
    "def filtrar_limpiar_personas(personas, ventas, mapeo_ids):\n",
    "    \"\"\"\n",
    "    ETL robusto sin _norm_num_str:\n",
    "    - Normaliza documento y tel√©fono.\n",
    "    - Elimina _id de Mongo.\n",
    "    - Solo conserva personas con ventas enlazables.\n",
    "    - Resuelve duplicados con sufijo incremental estable.\n",
    "    - Mapea idArticulo con mapeo_ids (normalizado).\n",
    "    - Descarta ventas sin comprador enlazable o con campos inv√°lidos.\n",
    "    Retorna (personas_limpias, ventas_finales).\n",
    "    \"\"\"\n",
    "\n",
    "    # ---- 0) Mapeo de art√≠culos: invertir + normalizar a int ----\n",
    "    mapeo_inverso = {}\n",
    "    for nuevo_id, ids_anteriores in (mapeo_ids or {}).items():\n",
    "        try:\n",
    "            nuevo_int = int(str(nuevo_id))\n",
    "        except Exception:\n",
    "            continue\n",
    "        for old in ids_anteriores or []:\n",
    "            try:\n",
    "                old_int = int(str(old))\n",
    "                mapeo_inverso[old_int] = nuevo_int\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "    # ---- 1) Preparar personas con id temporal y clave normalizada ----\n",
    "    personas_con_id_temp = []\n",
    "    id_temporal = 1\n",
    "\n",
    "    # doc_key (str del documento normalizado) -> lista[id_temp]\n",
    "    dockey_a_ids_temp = defaultdict(list)\n",
    "\n",
    "    for p in personas:\n",
    "        pc = dict(p)\n",
    "        pc.pop('_id', None)\n",
    "\n",
    "        num_doc = limpiar_valor_numerico(pc.get('numeroDocumento'))\n",
    "        if num_doc is None:\n",
    "            # No podremos emparejar esta persona\n",
    "            continue\n",
    "\n",
    "        doc_key = str(num_doc)  # <- reemplaza _norm_num_str\n",
    "\n",
    "        pc['_id_temp'] = id_temporal\n",
    "        pc['_doc_key'] = doc_key\n",
    "        dockey_a_ids_temp[doc_key].append(id_temporal)\n",
    "        personas_con_id_temp.append(pc)\n",
    "        id_temporal += 1\n",
    "\n",
    "    # ---- 2) Preasignar id_temp a ventas seg√∫n comprador normalizado ----\n",
    "    ventas_con_id_temp = []\n",
    "    for v in ventas:\n",
    "        vc = dict(v)\n",
    "        vc.pop('_id', None)\n",
    "\n",
    "        comp_num = limpiar_valor_numerico(vc.get('idComprador'))\n",
    "        if comp_num is not None:\n",
    "            comp_key = str(comp_num)  # <- reemplaza _norm_num_str\n",
    "            if dockey_a_ids_temp.get(comp_key):\n",
    "                vc['_id_temp_comprador'] = dockey_a_ids_temp[comp_key][0]  # determinista (primero)\n",
    "\n",
    "        ventas_con_id_temp.append(vc)\n",
    "\n",
    "    # ---- 3) Limpiar ventas y filtrar las enlazables ----\n",
    "    ventas_limpias = []\n",
    "    compradores_necesarios = set()\n",
    "\n",
    "    for v in ventas_con_id_temp:\n",
    "        # Campos num√©ricos obligatorios\n",
    "        id_venta    = limpiar_valor_numerico(v.get('idVenta'))\n",
    "        id_articulo = limpiar_valor_numerico(v.get('idArticulo'))\n",
    "        cantidad    = limpiar_valor_numerico(v.get('cantidadProductos'))\n",
    "\n",
    "        if id_venta is None or id_articulo is None or cantidad is None:\n",
    "            continue\n",
    "\n",
    "        # Mapear art√≠culo si corresponde\n",
    "        if id_articulo in mapeo_inverso:\n",
    "            id_articulo = mapeo_inverso[id_articulo]\n",
    "\n",
    "        # precioTotal robusto (permite s√≠mbolos)\n",
    "        raw_precio = str(v.get('precioTotal', 0))\n",
    "        raw_precio = re.sub(r'[^\\d.-]', '', raw_precio) or '0'\n",
    "        try:\n",
    "            precio_total = round(float(raw_precio), 2)\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "        # Necesitamos un id_temp de comprador v√°lido para garantizar FK\n",
    "        id_temp_comp = v.get('_id_temp_comprador')\n",
    "        if not id_temp_comp:\n",
    "            # Venta sin persona enlazable ‚Üí descartar (evita FK rota)\n",
    "            continue\n",
    "\n",
    "        compradores_necesarios.add(id_temp_comp)\n",
    "\n",
    "        # Cargar con placeholders; luego reemplazamos idComprador con doc final\n",
    "        v_clean = {\n",
    "            'idVenta': id_venta,\n",
    "            'idComprador': None,  # se asigna en el paso 5\n",
    "            'idArticulo': id_articulo,\n",
    "            'cantidadProductos': cantidad,\n",
    "            'precioTotal': precio_total,\n",
    "            '_id_temp_comprador': id_temp_comp\n",
    "        }\n",
    "        ventas_limpias.append(v_clean)\n",
    "\n",
    "    # ---- 4) Construir personas_limpias SOLO para compradores necesarios ----\n",
    "    personas_limpias = []\n",
    "    docs_usados = set()\n",
    "    contador_dups = defaultdict(int)  # num_doc_limpio -> contador\n",
    "    id_temp_a_doc_final = {}\n",
    "\n",
    "    for p in personas_con_id_temp:\n",
    "        if p['_id_temp'] not in compradores_necesarios:\n",
    "            continue\n",
    "\n",
    "        num_doc = limpiar_valor_numerico(p.get('numeroDocumento'))\n",
    "        if num_doc is None:\n",
    "            continue\n",
    "\n",
    "        # Resolver duplicados de forma determinista con sufijo incremental\n",
    "        if num_doc in docs_usados:\n",
    "            contador_dups[num_doc] += 1\n",
    "            num_doc_final = int(f\"{num_doc}{contador_dups[num_doc]}\")\n",
    "        else:\n",
    "            contador_dups[num_doc] = 0\n",
    "            num_doc_final = num_doc\n",
    "\n",
    "        docs_usados.add(num_doc_final)\n",
    "        id_temp_a_doc_final[p['_id_temp']] = num_doc_final\n",
    "\n",
    "        # Tel√©fono solo d√≠gitos o None\n",
    "        tel = p.get('telefono')\n",
    "        if tel is not None:\n",
    "            tel_digits = re.sub(r'[^\\d]', '', str(tel).strip())\n",
    "            p['telefono'] = tel_digits if tel_digits else None\n",
    "        else:\n",
    "            p['telefono'] = None\n",
    "\n",
    "        # Asignar documento final y limpiar temporales\n",
    "        p['numeroDocumento'] = num_doc_final\n",
    "        p.pop('_id_temp', None)\n",
    "        p.pop('_doc_key', None)\n",
    "\n",
    "        personas_limpias.append(p)\n",
    "\n",
    "    # ---- 5) Actualizar ventas con documento final del comprador ----\n",
    "    ventas_finales = []\n",
    "    for v in ventas_limpias:\n",
    "        id_temp = v.pop('_id_temp_comprador', None)\n",
    "        doc_final = id_temp_a_doc_final.get(id_temp)\n",
    "        if not doc_final:\n",
    "            # No deber√≠a ocurrir (ya filtramos), pero por seguridad\n",
    "            continue\n",
    "        v['idComprador'] = doc_final\n",
    "        ventas_finales.append(v)\n",
    "\n",
    "    return personas_limpias, ventas_finales\n",
    "\n",
    "\n",
    "\n",
    "personas = requests.get(\"http://localhost:8080/mongo/personas\").json()\n",
    "ventas = requests.get(\"http://localhost:8080/mongo/ventas\").json()\n",
    "\n",
    "personas_limpias, ventas_limpias = filtrar_limpiar_personas(personas, ventas, mapeo_ids)\n",
    "\n",
    "# Insertar en SQLite\n",
    "for persona in personas_limpias:\n",
    "    try:\n",
    "        response = requests.post(\"http://localhost:8080/sqlite/personas\", json=persona)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Error al insertar persona {persona.get('numeroDocumento')}: {response.json()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Excepci√≥n al insertar persona: {e}\")\n",
    "\n",
    "for venta in ventas_limpias:\n",
    "    try:\n",
    "        response = requests.post(\"http://localhost:8080/sqlite/ventas\", json=venta)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Error al insertar venta {venta.get('idVenta')}: {response.json()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Excepci√≥n al insertar venta: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener datos de MongoDB para ventas, escriba un ETL donde haga la validaci√≥n de idComprador, idArticulo y cantidadProductos asegurando que solo contengan valores \n",
    "# num√©ricos, tener en cuenta elimiar el id que proporciona DBMongo a cada uno de las colecciones para cargarla a la Bases de Datos Relacional en SQLlite que importo.\n",
    "\n",
    "\n",
    "# Obtener datos de MongoDB para ventas\n",
    "response = requests.get(\"http://localhost:8080/mongo/ventas\")\n",
    "ventas = response.json()\n",
    "ventas_limpias = filtrar_y_limpiar(ventas, 'idVenta', 'idComprador', 'idArticulo', 'cantidadProductos')\n",
    "print(json.dumps(ventas_limpias, ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"yellow\" size = \"4\" face = \"small fonts\">6. Muestre la data almacenada en la base de datos Relacional que esta usando, tabla por tabla.</font></center><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar data almacenada en la tabla personas\n",
    "# Conectar a la base de datos SQLite\n",
    "conexion = sqlite3.connect('../data/data/almacen.sqlite')\n",
    "\n",
    "# Crear una consulta SQL y cargar los resultados en un DataFrame\n",
    "consulta = \"SELECT * FROM personas;\"\n",
    "\n",
    "df = pd.read_sql_query(consulta, conexion)\n",
    "\n",
    "# Mostrar los datos\n",
    "print(df)\n",
    "\n",
    "# Cerrar la conexi√≥n\n",
    "conexion.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar data almacenada en la tabla articulos\n",
    "# Conectar a la base de datos SQLite\n",
    "conexion = sqlite3.connect('../data/data/almacen.sqlite')\n",
    "\n",
    "# Crear una consulta SQL y cargar los resultados en un DataFrame\n",
    "consulta = \"SELECT * FROM articulos\"\n",
    "df = pd.read_sql_query(consulta, conexion)\n",
    "\n",
    "# Mostrar los datos\n",
    "print(df)\n",
    "\n",
    "# Cerrar la conexi√≥n\n",
    "conexion.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar data almacenada en la tabla ventas\n",
    "# Conectar a la base de datos SQLite\n",
    "conexion = sqlite3.connect('../data/data/almacen.sqlite')\n",
    "\n",
    "# Crear una consulta SQL y cargar los resultados en un DataFrame\n",
    "consulta = \"SELECT * FROM ventas;\"\n",
    "df = pd.read_sql_query(consulta, conexion)\n",
    "\n",
    "# Mostrar los datos\n",
    "print(df)\n",
    "\n",
    "# Cerrar la conexi√≥n\n",
    "conexion.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"yellow\" size = \"4\" face = \"small fonts\">7. Grafique los 5 articulos mas vendidos.</font></center><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conectar a la base de datos\n",
    "conexion = sqlite3.connect('../data/data/almacen.sqlite') \n",
    "\n",
    "  # Ejecutar la consulta y cargar los datos en un DataFrame\n",
    "consulta = \"\"\"SELECT\n",
    "    a.idArticulo,\n",
    "    a.nombreArticulo,\n",
    "    SUM(v.cantidadProductos) AS unidades_vendidas,\n",
    "    SUM(v.precioTotal)      AS ingresos_totales\n",
    "    FROM ventas v\n",
    "    JOIN articulos a ON a.idArticulo = v.idArticulo\n",
    "    GROUP BY a.idArticulo, a.nombreArticulo\n",
    "    ORDER BY unidades_vendidas DESC, ingresos_totales DESC, a.nombreArticulo ASC\n",
    "    LIMIT 5;\"\"\"\n",
    "\n",
    "\n",
    "df = pd.read_sql_query(consulta, conexion)\n",
    "\n",
    "# Cerrar la conexi√≥n\n",
    "conexion.close()\n",
    "\n",
    "# Graficar los datos\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(df['nombreArticulo'], df['unidades_vendidas'], color='skyblue')\n",
    "plt.title('Top 5 Art√≠culos M√°s Vendidos')\n",
    "plt.xlabel('Art√≠culo')\n",
    "plt.ylabel('Unidades Vendidas')\n",
    "plt.xticks(rotation=45)\n",
    "plt.gca().yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"yellow\" size = \"4\" face = \"small fonts\">8. Grafique los 5 compradores que han realizado m√°s compras.</font></center><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conectar a la base de datos\n",
    "conexion = sqlite3.connect('../data/data/almacen.sqlite') \n",
    "\n",
    "# Ejecutar la consulta y cargar los datos en un DataFrame\n",
    "consulta = \"\"\"\n",
    "SELECT\n",
    "  p.numeroDocumento,\n",
    "  p.nombres,\n",
    "  p.primerApellido,\n",
    "  p.segundoApellido,\n",
    "  COUNT(*)                           AS compras_realizadas,\n",
    "  SUM(v.cantidadProductos)           AS unidades_compradas,\n",
    "  SUM(v.precioTotal)                 AS total_gastado\n",
    "FROM ventas v\n",
    "JOIN personas p ON p.numeroDocumento = v.idComprador\n",
    "GROUP BY p.numeroDocumento, p.nombres, p.primerApellido, p.segundoApellido\n",
    "ORDER BY unidades_compradas DESC, total_gastado DESC, p.primerApellido ASC, p.nombres ASC\n",
    "LIMIT 5;\n",
    "\"\"\"\n",
    "df = pd.read_sql_query(consulta, conexion)\n",
    "\n",
    "\n",
    "# Asegura tipos y arma el nombre completo de forma segura\n",
    "# Crear nombre completo del cliente\n",
    "df['cliente'] = (df['nombres'] + ' ' + df['primerApellido'] + ' ' + df['segundoApellido']).str.strip()\n",
    "\n",
    "# Graficar\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(df['cliente'], df['total_gastado'], color='lightcoral')\n",
    "plt.title('Top 5 Compradores que M√°s Han Comprado')\n",
    "plt.xlabel('Cliente')\n",
    "plt.ylabel('Total Gastado ($)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.gca().yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Cerrar la conexi√≥n\n",
    "conexion.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"yellow\" size = \"4\" face = \"small fonts\">9. Grafique la distribuci√≥n de precios de los 5 primeros art√≠culos .</font></center><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conectar a la base de datos\n",
    "conexion = sqlite3.connect('../data/data/almacen.sqlite') \n",
    "\n",
    "# Ejecutar la consulta y cargar los datos en un DataFrame\n",
    "consulta = \"\"\"\n",
    "SELECT\n",
    "  idArticulo,\n",
    "  nombreArticulo,\n",
    "  precioArticulo\n",
    "FROM articulos\n",
    "ORDER BY idArticulo ASC\n",
    "LIMIT 5;\n",
    "\"\"\"\n",
    "df = pd.read_sql_query(consulta, conexion)\n",
    "\n",
    "# Graficar\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(df['nombreArticulo'], df['precioArticulo'], color='lightgreen')\n",
    "plt.title('Distribuci√≥n de Precios de los 5 Primeros Art√≠culos')\n",
    "plt.xlabel('Art√≠culo')\n",
    "plt.ylabel('Precio ($)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Cerrar la conexi√≥n\n",
    "conexion.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"yellow\" size = \"4\" face = \"small fonts\">10. Grafique los 5 art√≠culos que menos se han vendido.</font></center><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conectar a la base de datos\n",
    "conexion = sqlite3.connect('../data/data/almacen.sqlite') \n",
    "\n",
    "# Ejecutar la consulta y cargar los datos en un DataFrame\n",
    "consulta = \"\"\"\n",
    "SELECT\n",
    "    a.idArticulo,\n",
    "    a.nombreArticulo,\n",
    "    COALESCE(SUM(v.cantidadProductos), 0) AS unidades_vendidas,\n",
    "    COALESCE(SUM(v.precioTotal), 0) AS ingresos_totales\n",
    "FROM articulos a\n",
    "LEFT JOIN ventas v ON a.idArticulo = v.idArticulo\n",
    "GROUP BY a.idArticulo, a.nombreArticulo\n",
    "ORDER BY unidades_vendidas ASC, ingresos_totales ASC, a.nombreArticulo ASC\n",
    "LIMIT 5;\n",
    "\"\"\"\n",
    "df = pd.read_sql_query(consulta, conexion)\n",
    "\n",
    "# Cerrar la conexi√≥n\n",
    "conexion.close()\n",
    "\n",
    "# Graficar los datos\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(df['nombreArticulo'], df['unidades_vendidas'], color='salmon')\n",
    "plt.title('Top 5 Art√≠culos Menos Vendidos')\n",
    "plt.xlabel('Art√≠culo')\n",
    "plt.ylabel('Unidades Vendidas')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.gca().yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
